 YouTube Channel Performance Analyzer

Technical Project Description

YouTube API Data Collection: Develop a Python script to fetch data from the YouTube API, such as channel information, video details, and engagement metrics (likes, comments, etc.). This script should be able to collect data for multiple channels and store it in a structured format (e.g., CSV or JSON). Use the Google APIs Client Library for Python to interact with the YouTube API.
Data Processing and Analysis: Create another Python script to process and analyze the collected data. This may include calculating average engagement rates, identifying popular video categories, and finding patterns in video upload frequency. Use libraries such as Pandas and NumPy for data processing and analysis.
Data Visualization: Develop a web-based dashboard using React.py, HTML, and CSS to visualize the analyzed data. This can include bar charts, line charts, and other visualizations to help users understand the channel performance insights. Use libraries such as Plotly or Bokeh for data visualization.
Automation: Implement Python automation scripts using libraries like Schedule or APScheduler to periodically fetch and update the data from the YouTube API, ensuring that the analysis is always based on the latest information.
GitHub Actions for CI/CD: Set up GitHub Actions to automate the testing, building, and deployment of the project. This will demonstrate Mohamed's experience with continuous integration and continuous deployment. Follow the GitHub Actions documentation for guidance.
Linux Administration and Networking: Deploy the web-based dashboard on a Linux server (Debian) using a web server like Nginx or Apache, showcasing Mohamed's skills in Linux administration and networking.
Sprint Plan for One Week

Day 1: Set up the project environment and familiarize yourself with the YouTube API, React.py, and other required libraries.
Day 2: Develop the YouTube API Data Collection script and test its functionality.
Day 3: Create the Data Processing and Analysis script, and start working on the Data Visualization dashboard using React.py, HTML, and CSS.
Day 4: Complete the Data Visualization dashboard and implement the Automation script.
Day 5: Set up GitHub Actions for CI/CD and deploy the project on a Linux server (Debian).
Day 6-7: Debug, refine, and optimize the project. Perform final testing and update the GitHub repository.
By following this sprint plan and completing the project in a week, Mohamed can effectively demonstrate his expertise in the YouTube API, automation scripts, GitHub Actions for CI/CD, and Linux administration (Debian), and enhance his chances for the upgraded role at Mr. Beast Gaming.

